# (1) êµ¬ê¸€ ë“œë¼ì´ë¸Œ ë§ˆìš´íŠ¸
from google.colab import drive
drive.mount('/content/drive')

____________________________________________________________________________________________________

# (2) ê°ì¢… ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸
import os
import json
import numpy as np
import cv2
import torch
import torch.optim as optim
import torchvision
import torchmetrics
import xml.etree.ElementTree as ET
import torchvision.transforms as T
import glob
import matplotlib.pyplot as plt
from PIL import Image
from torch.utils.data import Dataset, DataLoader
from torchvision.models.detection.faster_rcnn import FastRCNNPredictor
from torchvision.models.detection import fasterrcnn_resnet50_fpn
from torchmetrics.detection.mean_ap import MeanAveragePrecision
from torchvision.ops import box_iou
from sklearn.metrics import precision_recall_curve, average_precision_score
from tqdm import tqdm
%matplotlib inline

____________________________________________________________________________________________________

# (3) ì‚¬ìš©ì ì •ì˜ Dataset í´ë˜ìŠ¤ êµ¬í˜„
# XML ë¼ë²¨ë§ íŒŒì¼ì„ ì½ì–´ì„œ ì´ë¯¸ì§€ì™€ ë°”ìš´ë”© ë°•ìŠ¤ ì •ë³´ë¥¼ ì¶”ì¶œ
# object detection í•™ìŠµì„ ìœ„í•œ í˜•íƒœë¡œ ë°ì´í„° ì„¸íŒ…
# {"olive": 1, "anthracnose": 2}
class CustomDataset(Dataset) :

    def __init__(self, root, transforms=None, classes_mapping=None) :
        self.root = root # ì´ë¯¸ì§€ì™€ XML ë¼ë²¨ íŒŒì¼ì´ ìˆëŠ” ë””ë ‰í† ë¦¬ ê²½ë¡œ
        self.transforms = transforms
        self.xml_files = [os.path.join(root, f) for f in os.listdir(root) if f.endswith('.xml')] # ëª¨ë“  XML íŒŒì¼ ê²½ë¡œ

        # í´ë˜ìŠ¤ ì´ë¦„ -> ìˆ«ì ë¼ë²¨ ë§¤í•‘
        if classes_mapping is None :
            self.classes_mapping = {"olive": 1, "anthracnose": 2,}
        else :
            self.classes_mapping = classes_mapping

    def __len__(self) :
        # ë°ì´í„°ì…‹ì˜ í¬ê¸° = XML íŒŒì¼ ê°¯ìˆ˜
        return len(self.xml_files)

    def __getitem__(self, idx) :
        xml_path = self.xml_files[idx]
        tree = ET.parse(xml_path)
        root_elem = tree.getroot()

        # ì´ë¯¸ì§€ íŒŒì¼ëª… ì¶”ì¶œ
        # <filename> íƒœê·¸ì—ì„œ ì´ë¯¸ì§€ íŒŒì¼ ì´ë¦„ ì¶”ì¶œ
        image_file = root_elem.find('filename').text.strip()
        img_path = os.path.join(self.root, image_file)
        img = Image.open(img_path).convert("RGB") # RGB í˜•ì‹ìœ¼ë¡œ ì´ë¯¸ì§€ ë¡œë”©
        boxes = [] # ë°”ìš´ë”© ë°•ìŠ¤ ì¢Œí‘œ ë¦¬ìŠ¤íŠ¸
        labels = [] # í´ë˜ìŠ¤ ë¼ë²¨ ë¦¬ìŠ¤íŠ¸

        # <object> íƒœê·¸ ë°˜ë³µ (ê°ì²´ë§ˆë‹¤ ë°”ìš´ë”© ë°•ìŠ¤ì™€ í´ë˜ìŠ¤ ë¼ë²¨ ì¡´ì¬)
        for obj in root_elem.findall('object') :
            name = obj.find('name').text.strip() # í´ë˜ìŠ¤ ì´ë¦„
            label_val = self.classes_mapping.get(name, 0) # ë§¤í•‘ëœ ìˆ«ì ë¼ë²¨ (ì—†ìœ¼ë©´ 0ìœ¼ë¡œ) 
            labels.append(label_val)

            # ë°”ìš´ë”© ë°•ìŠ¤ ì¢Œí‘œ ì¶”ì¶œ
            bndbox = obj.find('bndbox')
            xmin = int(bndbox.find('xmin').text)
            ymin = int(bndbox.find('ymin').text)
            xmax = int(bndbox.find('xmax').text)
            ymax = int(bndbox.find('ymax').text)
            boxes.append([xmin, ymin, xmax, ymax])

        boxes = torch.as_tensor(boxes, dtype=torch.float32)
        labels = torch.as_tensor(labels, dtype=torch.int64)

        image_id = torch.tensor([idx]) # ì´ë¯¸ì§€ ê³ ìœ  ID (ì¸ë±ìŠ¤ ê¸°ì¤€)
        area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0]) # ë°”ìš´ë”© ë°•ìŠ¤ ë„“ì´ ê³„ì‚°
        iscrowd = torch.zeros((boxes.shape[0],), dtype=torch.int64)

        # ëª¨ë¸ í•™ìŠµì„ ìœ„í•œ target ë”•ì…”ë„ˆë¦¬ êµ¬ì„±
        target = {
            "boxes" : boxes,
            "labels" : labels,
            "image_id" : image_id,
            "area" : area,
            "iscrowd" : iscrowd
        }

        if self.transforms :
            img = self.transforms(img)

        return img, target # ì´ë¯¸ì§€ì™€ íƒ€ê²Ÿ ì •ë³´ ë°˜í™˜

# ë°ì´í„° ì „ì²˜ë¦¬ë¥¼ ìœ„í•œ transform í•¨ìˆ˜
def get_transform(train) :
    transforms = []
    transforms.append(T.ToTensor()) # PIL ì´ë¯¸ì§€ë¥¼ Tensorë¡œ ë³€í™˜
    if train :
        transforms.append(T.RandomHorizontalFlip(0.5)) # í•™ìŠµ ì‹œ ì¢Œìš°ë°˜ì „ (50% í™•ë¥ ë¡œ)
    return T.Compose(transforms) # ë³€í™˜ë“¤ì„ ìˆœì°¨ì ìœ¼ë¡œ ì ìš©

# ê° ë°ì´í„°ì…‹ í´ë” ê²½ë¡œ ì„¤ì •
train_path = "/content/drive/MyDrive/Colab/ACK2025/olive/train"
val_path   = "/content/drive/MyDrive/Colab/ACK2025/olive/validation"
test_path  = "/content/drive/MyDrive/Colab/ACK2025/olive/test"

dataset_train = CustomDataset(train_path, transforms=get_transform(train=True))
dataset_val   = CustomDataset(val_path, transforms=get_transform(train=False))
dataset_test  = CustomDataset(test_path, transforms=get_transform(train=False))

# object detectionì—ì„œëŠ” custom collate_fnì´ í•„ìš”
# ê¸°ë³¸ collateëŠ” í…ì„œë¥¼ ìŒ“ëŠ” ë°©ì‹ì¸ë°, detectionì—ì„œëŠ” ì´ë¯¸ì§€ì™€ targetì´ ê°ê° ë‹¤ë¥¸ í¬ê¸°ì´ë¯€ë¡œ ë¶ˆê°€ëŠ¥
# zip(*)ì„ ì´ìš©í•´ ì´ë¯¸ì§€ ë¦¬ìŠ¤íŠ¸ì™€ target ë¦¬ìŠ¤íŠ¸ë¡œ ë¬¶ì–´ì„œ ë°˜í™˜
def collate_fn(batch) :
    return tuple(zip(*batch))

# dataloader êµ¬ì„±
# batch_sizeëŠ” í•œ ë²ˆì— ì²˜ë¦¬í•  ì´ë¯¸ì§€ ê°œìˆ˜
# shuffle = true : í•™ìŠµ ë°ì´í„°ëŠ” ë§¤ epochë§ˆë‹¤ ì„ëŠ”ë‹¤.
# num_workers = 0 : ë°ì´í„° ë¡œë”© í”„ë¡œì„¸ìŠ¤ ìˆ˜ (ì½”ë©ì—ì„œëŠ” 0ì´ ì•ˆì „í•¨)
train_loader = DataLoader(dataset_train, batch_size=3, shuffle=True, num_workers=0, collate_fn=collate_fn)
val_loader   = DataLoader(dataset_val, batch_size=3, shuffle=False, num_workers=0, collate_fn=collate_fn)
test_loader  = DataLoader(dataset_test, batch_size=3, shuffle=False, num_workers=0, collate_fn=collate_fn)

# train_loaderì—ì„œ ì²« ë°°ì¹˜ ê°€ì ¸ì˜¤ê¸° (ë””ë²„ê¹…ìš©)
# images : ì´ë¯¸ì§€ í…ì„œ ë¦¬ìŠ¤íŠ¸
# targets : ê° ì´ë¯¸ì§€ì— ëŒ€ì‘í•˜ëŠ” ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸
images, targets = next(iter(train_loader))
print(f"Batch image type: {type(images[0])}, Batch target type: {type(targets[0])}")

____________________________________________________________________________________________________

# (4) torchvisionì˜ ì‚¬ì „í•™ìŠµëœ Faster R-CNN ëª¨ë¸(ResNet-50 FPN ê¸°ë°˜) ë¶ˆëŸ¬ì˜¤ê¸°
# ì‚¬ìš©ì ë°ì´í„°ì…‹ì— ë§ê²Œ ì¶œë ¥ í´ë˜ìŠ¤ë¥¼ ì¡°ì •í•˜ëŠ” í•¨ìˆ˜
def get_model_instance_segmentation(num_classes) :
    # ë°±ë³¸ : ResNet-50
    # FPN : Feature Pyramid Network (ë‹¤ì–‘í•œ í•´ìƒë„ì˜ íŠ¹ì§•ì„ ì¶”ì¶œ)
    # pretrained = True : COCO ë°ì´í„°ì…‹ìœ¼ë¡œ í•™ìŠµëœ ê°€ì¤‘ì¹˜ ì‚¬ìš©
    model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)

    # ê¸°ì¡´ ì¶œë ¥ ë ˆì´ì–´ í™•ì¸
    # ROI headì˜ box classifier ë¶€ë¶„ (í´ë˜ìŠ¤ ë¶„ë¥˜ê¸°)
    in_features = model.roi_heads.box_predictor.cls_score.in_features

    # box_predictor (í´ë˜ìŠ¤ ë¶„ë¥˜ê¸° + ë°”ìš´ë”© ë°•ìŠ¤ íšŒê·€ê¸°) êµì²´
    # FastRCNNPredictorëŠ” Pytorchê°€ ì œê³µí•˜ëŠ” ëª¨ë“ˆ
    # ì¶œë ¥ í´ë˜ìŠ¤ ìˆ˜ì— ë§ê²Œ ìƒˆë¡œìš´ predicotr ìƒì„±
    # num_classes : í´ë˜ìŠ¤ ìˆ˜ (ë°°ê²½ í¬í•¨ 3ê°œ : ë°°ê²½, olive, anthracnose)
    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)
    return model

# í´ë˜ìŠ¤ ë§¤í•‘
num_classes = 3
# ì‚¬ìš©ì ì •ì˜ í´ë˜ìŠ¤ ìˆ˜ë¡œ ëª¨ë¸ ìƒì„±
model = get_model_instance_segmentation(num_classes)
# ëª¨ë¸ì„ GPUë¡œ ì˜®ê¸°ê¸° (ê°€ëŠ¥í•˜ë©´ CUDA ì‚¬ìš©, ì•„ë‹ˆë©´ CPU)
model.to(torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu'))

____________________________________________________________________________________________________

# (5) í•™ìŠµ
device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')
model.to(device)

# ì˜µí‹°ë§ˆì´ì € ì„¤ì •
# SGD (í™•ë¥ ì  ê²½ì‚¬ í•˜ê°•ë²•) ì‚¬ìš©
# lr : í•™ìŠµë¥ , momentum : ê´€ì„±, weight_decay : L2 ì •ê·œí™”
optimizer = optim.SGD(model.parameters(), lr=0.005, momentum=0.9, weight_decay=0.0005)

# í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ëŸ¬ ì„¤ì •
# StepLR : ì¼ì • ì—í¬í¬ë§ˆë‹¤ í•™ìŠµë¥  ê°ì†Œ
# step_size = 3 : ë§¤ 3 ì—í¬í¬ë§ˆë‹¤
# gamma = 0.1 : í•™ìŠµë¥ ì„ 10ë¶„ì˜ 1ë¡œ ì¤„ì„
lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)

# ì²´í¬í¬ì¸íŠ¸ ë””ë ‰í† ë¦¬ ë° ë³€ìˆ˜ ì´ˆê¸°í™”
checkpoint_dir = "/content/drive/MyDrive/Colab/ACK2025/olive/model"
latest_checkpoint = None
start_epoch = 0 # ê¸°ë³¸ì ìœ¼ë¡œëŠ” ì²˜ìŒë¶€í„° í•™ìŠµí•˜ë„ë¡

# ì²´í¬í¬ì¸íŠ¸(pth íŒŒì¼) ë¶ˆëŸ¬ì˜¤ê¸° (í•™ìŠµ ì¬ì‹œì‘)
checkpoint_files = sorted(glob.glob(os.path.join(checkpoint_dir, "*.pth")))
if checkpoint_files :
    latest_checkpoint = checkpoint_files[-1]  # ê°€ì¥ ë§ˆì§€ë§‰ ì—í¬í¬ íŒŒì¼
    checkpoint = torch.load(latest_checkpoint)
    model.load_state_dict(checkpoint["model_state_dict"])
    optimizer.load_state_dict(checkpoint["optimizer_state_dict"])
    lr_scheduler.load_state_dict(checkpoint["lr_scheduler_state_dict"])
    start_epoch = checkpoint["epoch"] # ì´ì–´ì„œ í•™ìŠµí•  ì—í¬í¬ ì§€ì •
    print(f"{start_epoch} ì—í¬í¬ë¶€í„° í•™ìŠµì´ ì¬ê°œë©ë‹ˆë‹¤ ğŸ„")
else:
    print("ì²´í¬í¬ì¸íŠ¸ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤! í•™ìŠµì´ ì²˜ìŒë¶€í„° ì‹œì‘ë©ë‹ˆë‹¤ ğŸƒ")

# ì´ í•™ìŠµ ì—í¬í¬
num_epochs = 40

# í•™ìŠµ ë£¨í”„
for epoch in range(start_epoch, num_epochs) :
    model.train() # ëª¨ë¸ì„ í•™ìŠµ ëª¨ë“œë¡œ ì „í™˜
    train_loss_total = 0.0 # ì—í¬í¬ ë™ì•ˆì˜ ì´ loss ì´ˆê¸°í™”

    # í•™ìŠµ ë°ì´í„° ë°˜ë³µ
    for images, targets in train_loader :
        images = [img.to(device) for img in images]
        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]

        optimizer.zero_grad()
        # ëª¨ë¸ì— forward pass â†’ loss ê³„ì‚°
        loss_dict = model(images, targets) # ë°˜í™˜ê°’ : dict (classification, box regression ë“±)
        losses = sum(loss for loss in loss_dict.values()) # ëª¨ë“  loss í•©ì‚°
        train_loss_total += losses.item()

        losses.backward() # ì—­ì „íŒŒ
        optimizer.step() # íŒŒë¼ë¯¸í„° ì—…ë°ì´íŠ¸

    avg_train_loss = train_loss_total / len(train_loader) # í‰ê·  í•™ìŠµ ì†ì‹¤ ê³„ì‚°

    # ê²€ì¦
    model.eval() # ëª¨ë¸ì„ í‰ê°€ ëª¨ë“œë¡œ ì „í™˜
    val_loss_total = 0.0
    with torch.no_grad() : # ê²€ì¦ì€ gradient ê³„ì‚° ì—†ì´ ìˆ˜í–‰
        for images, targets in val_loader :
            images = [img.to(device) for img in images]
            outputs = model(images) # ì¶”ë¡  ìˆ˜í–‰ (loss ì—†ìŒ)

    print(f"ì—í¬í¬ {epoch+1}/{num_epochs}  -  í•™ìŠµ loss: {avg_train_loss:.4f}")

    # í•™ìŠµë¥  ì—…ë°ì´íŠ¸
    lr_scheduler.step() # ì„¤ì •í•œ step_sizeë§ˆë‹¤ í•™ìŠµë¥  ê°ì†Œ

    # ì²´í¬í¬ì¸íŠ¸ ì €ì¥ (ëª¨ë¸ + ì˜µí‹°ë§ˆì´ì € + í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ëŸ¬ ê°™ì´)
    checkpoint_path = f"/content/drive/MyDrive/Colab/ACK2025/olive/model/250703_epoch_{epoch+1}.pth"
    torch.save({
        "epoch": epoch + 1,  # ë°”ë¡œ ë‹¤ìŒ ì—í¬í¬ë¶€í„° ì‹œì‘í•  ìˆ˜ ìˆê²Œ
        "model_state_dict": model.state_dict(),  # ëª¨ë¸ ê°€ì¤‘ì¹˜
        "optimizer_state_dict": optimizer.state_dict(), # ì˜µí‹°ë§ˆì´ì € ìƒíƒœ
        "lr_scheduler_state_dict": lr_scheduler.state_dict() # ìŠ¤ì¼€ì¤„ëŸ¬ ìƒíƒœ
    }, checkpoint_path)

    print(f"{epoch+1} ì—í¬í¬, ì˜µí‹°ë§ˆì´ì €, í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ëŸ¬ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤ ğŸ€: {checkpoint_path}")

print("í›ˆë ¨ ì¢…ë£Œ ğŸŒ¿")
