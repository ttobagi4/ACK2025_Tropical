# (1) êµ¬ê¸€ ë“œë¼ì´ë¸Œ ë§ˆìš´íŠ¸
from google.colab import drive
drive.mount('/content/drive')

# (2) ê°ì¢… ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸
import os
import json
import numpy as np
import cv2
import torch
import torch.optim as optim
import torchvision
import torchmetrics
import xml.etree.ElementTree as ET
import torchvision.transforms as T
import glob
import matplotlib.pyplot as plt
from PIL import Image
from torch.utils.data import Dataset, DataLoader
from torchvision.models.detection.faster_rcnn import FastRCNNPredictor
from torchmetrics.detection.mean_ap import MeanAveragePrecision
%matplotlib inline

# (3) ì‚¬ìš©ì ì •ì˜ Dataset í´ë˜ìŠ¤ êµ¬í˜„
# root (str) : XML ë¼ë²¨ë§ íŒŒì¼ê³¼ ì´ë¯¸ì§€ê°€ ìˆëŠ” í´ë” ê²½ë¡œ
# transforms (callable, optional) : ì´ë¯¸ì§€ ì „ì²˜ë¦¬ & ë³€í™˜ í•¨ìˆ˜
# {"olive": 1, "anthracnose": 2}
class CustomDataset(Dataset) :

    def __init__(self, root, transforms=None, classes_mapping=None) :
        self.root = root
        self.transforms = transforms
        self.xml_files = [os.path.join(root, f) for f in os.listdir(root) if f.endswith('.xml')]

        if classes_mapping is None :
            self.classes_mapping = {"olive": 1, "anthracnose": 2,}
        else :
            self.classes_mapping = classes_mapping

    def __len__(self) :
        return len(self.xml_files)

    def __getitem__(self, idx) :
        xml_path = self.xml_files[idx]
        tree = ET.parse(xml_path)
        root_elem = tree.getroot()

        # ì´ë¯¸ì§€ íŒŒì¼ëª… ì¶”ì¶œ
        image_file = root_elem.find('filename').text.strip()
        # ì´ë¯¸ì§€ íŒŒì¼ì´ XML íŒŒì¼ê³¼ ê°™ì€ í´ë” ë‚´ì— ìˆë‹¤ê³  ê°€ì •
        img_path = os.path.join(self.root, image_file)
        img = Image.open(img_path).convert("RGB")
        boxes = []
        labels = []

        # XML íŒŒì¼ì˜ ëª¨ë“  object íƒœê·¸ ì²˜ë¦¬ (ê°ì²´ë§ˆë‹¤ ë°”ìš´ë”© ë°•ìŠ¤ & í´ë˜ìŠ¤ ì •ë³´)
        for obj in root_elem.findall('object') :
            name = obj.find('name').text.strip()
            label_val = self.classes_mapping.get(name, 0)
            labels.append(label_val)

            bndbox = obj.find('bndbox')
            xmin = int(bndbox.find('xmin').text)
            ymin = int(bndbox.find('ymin').text)
            xmax = int(bndbox.find('xmax').text)
            ymax = int(bndbox.find('ymax').text)
            boxes.append([xmin, ymin, xmax, ymax])

        boxes = torch.as_tensor(boxes, dtype=torch.float32)
        labels = torch.as_tensor(labels, dtype=torch.int64)

        image_id = torch.tensor([idx])
        area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])
        iscrowd = torch.zeros((boxes.shape[0],), dtype=torch.int64)

        target = {
            "boxes" : boxes,
            "labels" : labels,
            "image_id" : image_id,
            "area" : area,
            "iscrowd" : iscrowd
        }

        if self.transforms :
            img = self.transforms(img)

        return img, target

# ë³€í™˜ í•¨ìˆ˜ ì„¤ì • (í•™ìŠµ ì‹œì™€ ê²€ì¦/í…ŒìŠ¤íŠ¸ ì‹œ ì°¨ì´ê°€ ìˆì„ ìˆ˜ ìˆìŒ)
def get_transform(train) :
    transforms = []
    transforms.append(T.ToTensor())
    if train :
        transforms.append(T.RandomHorizontalFlip(0.5))
    return T.Compose(transforms)

# ê° ë°ì´í„°ì…‹ í´ë” ê²½ë¡œ ì„¤ì •
train_path = "/content/drive/MyDrive/Colab/ACK2025/olive/train"
val_path   = "/content/drive/MyDrive/Colab/ACK2025/olive/validation"
test_path  = "/content/drive/MyDrive/Colab/ACK2025/olive/test"

dataset_train = CustomDataset(train_path, transforms=get_transform(train=True))
dataset_val   = CustomDataset(val_path, transforms=get_transform(train=False))
dataset_test  = CustomDataset(test_path, transforms=get_transform(train=False))

# DataLoader ìƒì„± (object detection ëª¨ë¸ì€ collate_fn í•„ìš”í•¨)
# detection ëª¨ë¸ì€ ì´ë¯¸ì§€ì™€ íƒ€ê²Ÿì´ ë¦¬ìŠ¤íŠ¸ í˜•íƒœë¡œ ë¬¶ì—¬ì•¼ í•˜ë¯€ë¡œ, zip(*)ìœ¼ë¡œ ë¬¶ì–´ì„œ ë°˜í™˜
def collate_fn(batch) :
    return tuple(zip(*batch))

train_loader = DataLoader(dataset_train, batch_size=3, shuffle=True, num_workers=0, collate_fn=collate_fn)
val_loader   = DataLoader(dataset_val, batch_size=3, shuffle=False, num_workers=0, collate_fn=collate_fn)
test_loader  = DataLoader(dataset_test, batch_size=3, shuffle=False, num_workers=0, collate_fn=collate_fn)

# train_loaderì˜ ì²« ë°°ì¹˜ì—ì„œ ì´ë¯¸ì§€ì™€ íƒ€ê²Ÿ ì •ë³´ í™•ì¸
images, targets = next(iter(train_loader))
print(f"Batch image type: {type(images[0])}, Batch target type: {type(targets[0])}")

# (4) torchvisionì˜ ì‚¬ì „í•™ìŠµëœ Faster R-CNN ëª¨ë¸(ResNet-50 FPN ê¸°ë°˜) ë¶ˆëŸ¬ì˜¤ê¸°
def get_model_instance_segmentation(num_classes) :
    model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)
    in_features = model.roi_heads.box_predictor.cls_score.in_features
    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)
    return model

# í´ë˜ìŠ¤ ë§¤í•‘
num_classes = 3
model = get_model_instance_segmentation(num_classes)
model.to(torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu'))

# (5) ì˜µí‹°ë§ˆì´ì € ë° í•™ìŠµ
device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')
model.to(device)

# ì˜µí‹°ë§ˆì´ì € & learning rate scheduler ì„¤ì •
optimizer = optim.SGD(model.parameters(), lr=0.005, momentum=0.9, weight_decay=0.0005)
lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)

checkpoint_dir = "/content/drive/MyDrive/Colab/ACK2025/olive/model"
latest_checkpoint = None
start_epoch = 0 # ê¸°ë³¸ì ìœ¼ë¡œëŠ” ì²˜ìŒë¶€í„° í•™ìŠµí•˜ë„ë¡

checkpoint_files = sorted(glob.glob(os.path.join(checkpoint_dir, "*.pth")))
if checkpoint_files :
    latest_checkpoint = checkpoint_files[-1]  # ê°€ì¥ ë§ˆì§€ë§‰ ì—í¬í¬ íŒŒì¼
    checkpoint = torch.load(latest_checkpoint)
    model.load_state_dict(checkpoint["model_state_dict"])
    optimizer.load_state_dict(checkpoint["optimizer_state_dict"])
    lr_scheduler.load_state_dict(checkpoint["lr_scheduler_state_dict"])
    start_epoch = checkpoint["epoch"]
    print(f"{start_epoch} ì—í¬í¬ë¶€í„° í•™ìŠµì´ ì¬ê°œë©ë‹ˆë‹¤ ğŸ„")
else:
    print("ì²´í¬í¬ì¸íŠ¸ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤! í•™ìŠµì´ ì²˜ìŒë¶€í„° ì‹œì‘ë©ë‹ˆë‹¤ ğŸƒ")

# ì´ í•™ìŠµ ì—í¬í¬
num_epochs = 40

for epoch in range(start_epoch, num_epochs) :
    # í•™ìŠµ
    model.train()
    train_loss_total = 0.0

    for images, targets in train_loader :
        images = [img.to(device) for img in images]
        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]

        optimizer.zero_grad()
        loss_dict = model(images, targets)
        losses = sum(loss for loss in loss_dict.values())
        train_loss_total += losses.item()

        losses.backward()
        optimizer.step()

    avg_train_loss = train_loss_total / len(train_loader)

    # ê²€ì¦
    model.eval()
    val_loss_total = 0.0
    with torch.no_grad() :
        for images, targets in val_loader :
            images = [img.to(device) for img in images]
            outputs = model(images)

    print(f"ì—í¬í¬ {epoch+1}/{num_epochs}  -  í•™ìŠµ loss: {avg_train_loss:.4f}")

    # learning rate scheduler ì—…ë°ì´íŠ¸
    lr_scheduler.step()

    # ëª¨ë¸ + ì˜µí‹°ë§ˆì´ì € + í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ëŸ¬ - ê°™ì´ ì €ì¥
    checkpoint_path = f"/content/drive/MyDrive/Colab/ACK2025/olive/model/250703_epoch_{epoch+1}.pth"
    torch.save({
        "epoch": epoch + 1,  # ë°”ë¡œ ë‹¤ìŒ ì—í¬í¬ë¶€í„° ì‹œì‘í•  ìˆ˜ ìˆê²Œ
        "model_state_dict": model.state_dict(),
        "optimizer_state_dict": optimizer.state_dict(),
        "lr_scheduler_state_dict": lr_scheduler.state_dict()
    }, checkpoint_path)

    print(f"{epoch+1} ì—í¬í¬, ì˜µí‹°ë§ˆì´ì €, í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ëŸ¬ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤ ğŸ€: {checkpoint_path}")

print("í›ˆë ¨ ì¢…ë£Œ ğŸŒ¿")
