# (1) 구글 드라이브 마운트
from google.colab import drive
drive.mount('/content/drive')

# (2) 각종 라이브러리 임포트
import os
import json
import numpy as np
import cv2
import torch
import torch.optim as optim
import torchvision
import torchmetrics
import xml.etree.ElementTree as ET
import torchvision.transforms as T
import glob
import matplotlib.pyplot as plt
from PIL import Image
from torch.utils.data import Dataset, DataLoader
from torchvision.models.detection.faster_rcnn import FastRCNNPredictor
from torchmetrics.detection.mean_ap import MeanAveragePrecision
%matplotlib inline

# (3) 사용자 정의 Dataset 클래스 구현
# root (str) : XML 라벨링 파일과 이미지가 있는 폴더 경로
# transforms (callable, optional) : 이미지 전처리 & 변환 함수
# {"olive": 1, "anthracnose": 2}
class CustomDataset(Dataset) :

    def __init__(self, root, transforms=None, classes_mapping=None) :
        self.root = root
        self.transforms = transforms
        self.xml_files = [os.path.join(root, f) for f in os.listdir(root) if f.endswith('.xml')]

        if classes_mapping is None :
            self.classes_mapping = {"olive": 1, "anthracnose": 2,}
        else :
            self.classes_mapping = classes_mapping

    def __len__(self) :
        return len(self.xml_files)

    def __getitem__(self, idx) :
        xml_path = self.xml_files[idx]
        tree = ET.parse(xml_path)
        root_elem = tree.getroot()

        # 이미지 파일명 추출
        image_file = root_elem.find('filename').text.strip()
        # 이미지 파일이 XML 파일과 같은 폴더 내에 있다고 가정
        img_path = os.path.join(self.root, image_file)
        img = Image.open(img_path).convert("RGB")
        boxes = []
        labels = []

        # XML 파일의 모든 object 태그 처리 (객체마다 바운딩 박스 & 클래스 정보)
        for obj in root_elem.findall('object') :
            name = obj.find('name').text.strip()
            label_val = self.classes_mapping.get(name, 0)
            labels.append(label_val)

            bndbox = obj.find('bndbox')
            xmin = int(bndbox.find('xmin').text)
            ymin = int(bndbox.find('ymin').text)
            xmax = int(bndbox.find('xmax').text)
            ymax = int(bndbox.find('ymax').text)
            boxes.append([xmin, ymin, xmax, ymax])

        boxes = torch.as_tensor(boxes, dtype=torch.float32)
        labels = torch.as_tensor(labels, dtype=torch.int64)

        image_id = torch.tensor([idx])
        area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])
        iscrowd = torch.zeros((boxes.shape[0],), dtype=torch.int64)

        target = {
            "boxes" : boxes,
            "labels" : labels,
            "image_id" : image_id,
            "area" : area,
            "iscrowd" : iscrowd
        }

        if self.transforms :
            img = self.transforms(img)

        return img, target

# 변환 함수 설정 (학습 시와 검증/테스트 시 차이가 있을 수 있음)
def get_transform(train) :
    transforms = []
    transforms.append(T.ToTensor())
    if train :
        transforms.append(T.RandomHorizontalFlip(0.5))
    return T.Compose(transforms)

# 각 데이터셋 폴더 경로 설정
train_path = "/content/drive/MyDrive/Colab/ACK2025/olive/train"
val_path   = "/content/drive/MyDrive/Colab/ACK2025/olive/validation"
test_path  = "/content/drive/MyDrive/Colab/ACK2025/olive/test"

dataset_train = CustomDataset(train_path, transforms=get_transform(train=True))
dataset_val   = CustomDataset(val_path, transforms=get_transform(train=False))
dataset_test  = CustomDataset(test_path, transforms=get_transform(train=False))

# DataLoader 생성 (object detection 모델은 collate_fn 필요함)
# detection 모델은 이미지와 타겟이 리스트 형태로 묶여야 하므로, zip(*)으로 묶어서 반환
def collate_fn(batch) :
    return tuple(zip(*batch))

train_loader = DataLoader(dataset_train, batch_size=3, shuffle=True, num_workers=0, collate_fn=collate_fn)
val_loader   = DataLoader(dataset_val, batch_size=3, shuffle=False, num_workers=0, collate_fn=collate_fn)
test_loader  = DataLoader(dataset_test, batch_size=3, shuffle=False, num_workers=0, collate_fn=collate_fn)

# train_loader의 첫 배치에서 이미지와 타겟 정보 확인
images, targets = next(iter(train_loader))
print(f"Batch image type: {type(images[0])}, Batch target type: {type(targets[0])}")

# (4) torchvision의 사전학습된 Faster R-CNN 모델(ResNet-50 FPN 기반) 불러오기
def get_model_instance_segmentation(num_classes) :
    model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)
    in_features = model.roi_heads.box_predictor.cls_score.in_features
    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)
    return model

# 클래스 매핑
num_classes = 3
model = get_model_instance_segmentation(num_classes)
model.to(torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu'))

# (5) 옵티마이저 및 학습
device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')
model.to(device)

# 옵티마이저 & learning rate scheduler 설정
optimizer = optim.SGD(model.parameters(), lr=0.005, momentum=0.9, weight_decay=0.0005)
lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)

checkpoint_dir = "/content/drive/MyDrive/Colab/ACK2025/olive/model"
latest_checkpoint = None
start_epoch = 0 # 기본적으로는 처음부터 학습하도록

checkpoint_files = sorted(glob.glob(os.path.join(checkpoint_dir, "*.pth")))
if checkpoint_files :
    latest_checkpoint = checkpoint_files[-1]  # 가장 마지막 에포크 파일
    checkpoint = torch.load(latest_checkpoint)
    model.load_state_dict(checkpoint["model_state_dict"])
    optimizer.load_state_dict(checkpoint["optimizer_state_dict"])
    lr_scheduler.load_state_dict(checkpoint["lr_scheduler_state_dict"])
    start_epoch = checkpoint["epoch"]
    print(f"{start_epoch} 에포크부터 학습이 재개됩니다 🍄")
else:
    print("체크포인트를 찾지 못했습니다! 학습이 처음부터 시작됩니다 🍃")

# 총 학습 에포크
num_epochs = 40

for epoch in range(start_epoch, num_epochs) :
    # 학습
    model.train()
    train_loss_total = 0.0

    for images, targets in train_loader :
        images = [img.to(device) for img in images]
        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]

        optimizer.zero_grad()
        loss_dict = model(images, targets)
        losses = sum(loss for loss in loss_dict.values())
        train_loss_total += losses.item()

        losses.backward()
        optimizer.step()

    avg_train_loss = train_loss_total / len(train_loader)

    # 검증
    model.eval()
    val_loss_total = 0.0
    with torch.no_grad() :
        for images, targets in val_loader :
            images = [img.to(device) for img in images]
            outputs = model(images)

    print(f"에포크 {epoch+1}/{num_epochs}  -  학습 loss: {avg_train_loss:.4f}")

    # learning rate scheduler 업데이트
    lr_scheduler.step()

    # 모델 + 옵티마이저 + 학습률 스케줄러 - 같이 저장
    checkpoint_path = f"/content/drive/MyDrive/Colab/ACK2025/olive/model/250703_epoch_{epoch+1}.pth"
    torch.save({
        "epoch": epoch + 1,  # 바로 다음 에포크부터 시작할 수 있게
        "model_state_dict": model.state_dict(),
        "optimizer_state_dict": optimizer.state_dict(),
        "lr_scheduler_state_dict": lr_scheduler.state_dict()
    }, checkpoint_path)

    print(f"{epoch+1} 에포크, 옵티마이저, 학습률 스케줄러가 저장되었습니다 🍀: {checkpoint_path}")

print("훈련 종료 🌿")
